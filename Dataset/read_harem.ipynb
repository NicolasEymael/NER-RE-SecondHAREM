{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Dataframe from XML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = []\n",
    "with open(\"CDSegundoHAREMReRelEM_UTF8.xml\", \"r\", encoding='UTF-8') as file:\n",
    "    # Read each line in the file, readlines() returns a list of lines\n",
    "    content = file.readlines()\n",
    "    # Combine the lines in the list into a string\n",
    "    content = \"\".join(content)\n",
    "    soup = bs(content, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(text):\n",
    "    text = \" \".join(text.split())\n",
    "    text = text.replace(\"\\n\", \"\")\n",
    "    text = text.strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "index_p = 0\n",
    "\n",
    "for index_doc, doc in enumerate(soup.find_all('doc')):\n",
    "    _id_doc = None\n",
    "    \n",
    "    if \"docid\" in doc.attrs:\n",
    "        _id_doc = doc.attrs[\"docid\"]\n",
    "                                \n",
    "    for p in doc.find_all('p'):\n",
    "        sentence_text_raw = p.text\n",
    "        sentence_text_processed = process_text(sentence_text_raw)\n",
    "        entities = []\n",
    "        \n",
    "        for index_em, em in enumerate(p.find_all('em')):\n",
    "            _entity = process_text(em.text)\n",
    "            _id = None\n",
    "            _categ = None\n",
    "            _tipo = None\n",
    "            _tiporel = None\n",
    "            _corel = None\n",
    "            _subtipo = None\n",
    "            if \"id\" in em.attrs:\n",
    "                _id = em.attrs[\"id\"]\n",
    "            if \"categ\" in em.attrs:\n",
    "                _categ = em.attrs[\"categ\"]\n",
    "            if \"tipo\" in em.attrs:\n",
    "                _tipo = em.attrs[\"tipo\"]\n",
    "            if \"subtipo\" in em.attrs:\n",
    "                _subtipo = em.attrs[\"subtipo\"]\n",
    "            if \"tiporel\" in em.attrs:\n",
    "                _tiporel = em.attrs[\"tiporel\"]\n",
    "            if \"corel\" in em.attrs:\n",
    "                _corel = em.attrs[\"corel\"]\n",
    "            \n",
    "            # Remover as entidades que não possuem categoria\n",
    "            if (_categ):\n",
    "                d = {\n",
    "                    \"doc_id\": _id_doc,\n",
    "                    \"doc_index\": index_doc,\n",
    "                    \"p_sentence_processed\": sentence_text_processed,\n",
    "                    \"p_index\": index_p,\n",
    "                    \"entity\": _entity,\n",
    "                    \"entity_id\": _id,\n",
    "                    \"entity_index\": index_em,\n",
    "                    \"categ\": _categ,\n",
    "                    \"tipo\": _tipo,\n",
    "                    \"subtipo\": _subtipo,\n",
    "                    \"tipo_final\": None, # será preenchido depois\n",
    "                    \"tiporel\": _tiporel,\n",
    "                    \"corel\": _corel\n",
    "                }\n",
    "                data.append(d)\n",
    "        index_p += 1\n",
    "        \n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df.to_csv(\"dataset_original.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Process Dataframe to simplify stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1- Remover todos os objetos de relações que sejam entidades ALT (versões alternativas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row, value in enumerate(df['corel'].tolist()):\n",
    "    # se o valor 'corel' da entidade nao é nulo...\n",
    "    if (value):\n",
    "\n",
    "        # separa cada objeto corel em uma lista\n",
    "        corel_list = value.split()\n",
    "        tiporel_list = df.at[row, 'tiporel'].split()\n",
    "        \n",
    "        final_corel_list = []\n",
    "        final_tiporel_list = []\n",
    "\n",
    "        for corel_index, corel in enumerate(corel_list):\n",
    "            # se o objeto corel termina com \"a\", \"b\", \"c\" ou \"d\" entao é uma entidade alternativa\n",
    "            # remover ele da lista de 'corel' e 'tiporel'\n",
    "            if not (corel.endswith((\"a\", \"b\", \"c\", \"d\"))):\n",
    "                final_corel_list.append(corel)\n",
    "                if (corel_index < len(tiporel_list)):\n",
    "                    final_tiporel_list.append(tiporel_list[corel_index])\n",
    "            \n",
    "        df.at[row, 'corel'] = \" \".join(final_corel_list)\n",
    "        df.at[row, 'tiporel'] = \" \".join(final_tiporel_list)\n",
    "    \n",
    "df.to_csv(\"dataset_processed_1.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2- Formatar as relações que possuem dados adicionais (ex: ACONTECIMENTO\\*\\*outrarel\\*\\*H2-dftre765-102\\*\\*OUTRO vai ficar apenas \"outrarel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row, value in enumerate(df['tiporel'].tolist()):\n",
    "    # se o valor 'tiporel' da entidade nao é nulo...\n",
    "    if (value):\n",
    "\n",
    "        # separa cada relação em uma lista\n",
    "        tiporel_list = value.split()\n",
    "        \n",
    "        final_tiporel_list = []\n",
    "\n",
    "        for tiporel_index, tiporel in enumerate(tiporel_list):\n",
    "            if (\"*\" in tiporel):\n",
    "                words_list = tiporel.split(\"**\")\n",
    "                relation = words_list[1]\n",
    "                final_tiporel_list.append(relation)\n",
    "            else:\n",
    "                final_tiporel_list.append(tiporel)\n",
    "            \n",
    "            df.at[row, 'tiporel'] = \" \".join(final_tiporel_list)\n",
    "    \n",
    "df.to_csv(\"dataset_processed_2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3- Simplificar a Categoria, Tipo e Subtipo em um tipo final escolhido (arbitrariamente)\n",
    "\n",
    "VALOR = valor\n",
    "\n",
    "TEMPO = tempo\n",
    "\n",
    "PESSOA + INDIVIDUAL ou CARGO = individuo\n",
    "\n",
    "PESSOA + GRUPOIND ou GRUPOCARGO ou GRUPOMEMBRO ou POVO ou MEMBRO = grupo\n",
    "\n",
    "OUTRO = outro\n",
    "\n",
    "ORGANIZACAO = organizacao\n",
    "\n",
    "OBRA = obra\n",
    "\n",
    "LOCAL + VIRTUAL + OBRA = obra\n",
    "\n",
    "LOCAL + VIRTUAL = virtual\n",
    "\n",
    "LOCAL + resto = local\n",
    "\n",
    "COISA = coisa\n",
    "\n",
    "ACONTECIMENTO = acontecimento\n",
    "\n",
    "ABSTRACCAO + DISCIPLINA = disciplina\n",
    "\n",
    "ABSTRACCAO + resto = abstraccao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_type(categ, tipo, subtipo):\n",
    "    if (categ == \"VALOR\"):\n",
    "        return \"valor\"\n",
    "    elif (categ == \"TEMPO\"):\n",
    "        return \"tempo\"\n",
    "    elif (categ == \"OUTRO\"):\n",
    "        return \"outro\"\n",
    "    elif (categ == \"ORGANIZACAO\"):\n",
    "        return \"organizacao\"\n",
    "    elif (categ == \"OBRA\"):\n",
    "        return \"obra\"\n",
    "    elif (categ == \"COISA\"):\n",
    "        return \"coisa\"\n",
    "    elif (categ == \"ACONTECIMENTO\"):\n",
    "        return \"acontecimento\"\n",
    "    elif (categ == \"PESSOA\"):\n",
    "        if (tipo == \"INDIVIDUAL\" or tipo == \"CARGO\"):\n",
    "            return \"individuo\"\n",
    "        else:\n",
    "            return \"grupo\"\n",
    "    elif (categ == \"LOCAL\"):\n",
    "        if (tipo == \"VIRTUAL\"):\n",
    "            if (subtipo == \"OBRA\"):\n",
    "                return \"obra\"\n",
    "            else:\n",
    "                return \"virtual\"\n",
    "        else:\n",
    "            return \"local\"\n",
    "    elif (categ == \"ABSTRACCAO\"):\n",
    "        if (tipo == \"DISCIPLINA\"):\n",
    "            return \"disciplina\"\n",
    "        else:\n",
    "            return \"abstraccao\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row, value in enumerate(df['categ'].tolist()):\n",
    "    # separa cada categ em uma lista (pode ter entidades com mais de uma categoria)\n",
    "    categ_list = value.split(\"|\")\n",
    "    \n",
    "    # pega os tipos e subtipos relacionados a categoria (verificar se existe tipo e subtipo antes...)\n",
    "    tipo_list = []\n",
    "    if (df.at[row, 'tipo']):\n",
    "        tipo_list = df.at[row, 'tipo'].split(\"|\")\n",
    "    subtipo_list = []\n",
    "    if (df.at[row, 'subtipo']):\n",
    "        subtipo_list = df.at[row, 'subtipo'].split(\"|\")\n",
    "\n",
    "    final_type_list = []\n",
    "\n",
    "    # para cada categ na lista, pegar o tipo e subtipo (se houver) e inferir o final_type\n",
    "    for categ_index, categ in enumerate(categ_list):\n",
    "        tipo = None\n",
    "        if (categ_index < len(tipo_list)):\n",
    "            tipo = tipo_list[categ_index]\n",
    "            \n",
    "        subtipo = None\n",
    "        if (categ_index < len(subtipo_list)):\n",
    "            subtipo = subtipo_list[categ_index]\n",
    "        \n",
    "        final_type = get_final_type(categ, tipo, subtipo)\n",
    "        \n",
    "        final_type_list.append(final_type)\n",
    "\n",
    "    df.at[row, 'tipo_final'] = \"|\".join(final_type_list)\n",
    "    \n",
    "df.to_csv(\"dataset_processed_3.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4- Remover os multitipos, cada entidade terá UM e APENAS UM tipo final, na seguinte prioridade:\n",
    "    1º: individuo\n",
    "    2º: virtual\n",
    "    3º: local\n",
    "    4º: organizacao\n",
    "    5º: grupo\n",
    "    6º: obra\n",
    "    7°: acontecimento\n",
    "    8°: disciplina\n",
    "    9°: tempo\n",
    "    10°: valor\n",
    "    11°: abstraccao\n",
    "    12°: coisa\n",
    "    13°: outro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "priority_list = [\n",
    "    \"individuo\",\n",
    "    \"virtual\",\n",
    "    \"local\",\n",
    "    \"organizacao\",\n",
    "    \"grupo\",\n",
    "    \"obra\",\n",
    "    \"acontecimento\",\n",
    "    \"disciplina\",\n",
    "    \"tempo\",\n",
    "    \"valor\",\n",
    "    \"abstraccao\",\n",
    "    \"coisa\",\n",
    "    \"outro\",\n",
    "]\n",
    "\n",
    "for row, value in enumerate(df['tipo_final'].tolist()):\n",
    "    # separa cada tipo_final em uma lista (pode ter entidades com mais de um tipo_final)\n",
    "    tipo_list = value.split(\"|\")\n",
    "    \n",
    "    result_index = 99\n",
    "    \n",
    "    for tipo in tipo_list:\n",
    "        current_priority_index = priority_list.index(tipo)\n",
    "        \n",
    "        # atualiza o tipo final apenas se o novo tipo tiver mais prioridade\n",
    "        if (current_priority_index < result_index):\n",
    "            result_index = current_priority_index\n",
    "    \n",
    "    result = priority_list[result_index]\n",
    "\n",
    "    df.at[row, 'tipo_final'] = result\n",
    "    \n",
    "df.to_csv(\"dataset_processed_4.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5- Adicionar a relação IDENT entre as entidades quando uma entidade é ALT da outra (possui um sufixo \"a\",\"b\",\"c\",\"d\")\n",
    "NOT IMPLEMENTED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for row, value in enumerate(df['entity_id'].tolist()):\n",
    "#    if (value.endswith((\"a\", \"b\", \"c\", \"d\"))):\n",
    "#        entity = df.at[row, \"entity\"]\n",
    "#        \n",
    "#        tiporel = df.at[row, \"tiporel\"]\n",
    "#        \n",
    "#        other_id = value.rstrip(\"abcd-\")\n",
    "#        \n",
    "#        other_entity = df.loc[df.entity_id == other_id, \"entity\"].values[0]\n",
    "#        \n",
    "#        other_tiporel = df.loc[df.entity_id == other_id, \"tiporel\"].values\n",
    "#        \n",
    "#        print(value)\n",
    "#        print(entity)\n",
    "#        print(tiporel)\n",
    "#        print(other_id)\n",
    "#        print(other_entity)\n",
    "#        print(other_tiporel)\n",
    "#        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show entity class distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DISTRIBUIÇÃO COM 13 CLASSES DE ENTIDADES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL = 7817\n",
      "INDIVIDUO = 1774\n",
      "VIRTUAL = 59\n",
      "LOCAL = 1480\n",
      "ORGANIZACAO = 1106\n",
      "GRUPO = 353\n",
      "OBRA = 489\n",
      "ACONTECIMENTO = 323\n",
      "DISCIPLINA = 182\n",
      "TEMPO = 1199\n",
      "VALOR = 352\n",
      "ABSTRACCAO = 110\n",
      "COISA = 311\n",
      "OUTRO = 79\n"
     ]
    }
   ],
   "source": [
    "individuo_cnt = 0\n",
    "virtual_cnt = 0\n",
    "local_cnt = 0\n",
    "organizacao_cnt = 0\n",
    "grupo_cnt = 0\n",
    "obra_cnt = 0\n",
    "acontecimento_cnt = 0\n",
    "disciplina_cnt = 0\n",
    "tempo_cnt = 0\n",
    "valor_cnt = 0\n",
    "abstraccao_cnt = 0\n",
    "coisa_cnt = 0\n",
    "outro_cnt = 0\n",
    "total_cnt = 0\n",
    "\n",
    "for tipo in df['tipo_final']:\n",
    "    total_cnt += 1\n",
    "    \n",
    "    if (tipo == \"individuo\"):\n",
    "        individuo_cnt += 1\n",
    "    elif (tipo == \"virtual\"):\n",
    "        virtual_cnt += 1\n",
    "    elif (tipo == \"local\"):\n",
    "        local_cnt += 1\n",
    "    elif (tipo == \"organizacao\"):\n",
    "        organizacao_cnt += 1\n",
    "    elif (tipo == \"grupo\"):\n",
    "        grupo_cnt += 1\n",
    "    elif (tipo == \"obra\"):\n",
    "        obra_cnt += 1\n",
    "    elif (tipo == \"acontecimento\"):\n",
    "        acontecimento_cnt += 1\n",
    "    elif (tipo == \"disciplina\"):\n",
    "        disciplina_cnt += 1\n",
    "    elif (tipo == \"tempo\"):\n",
    "        tempo_cnt += 1\n",
    "    elif (tipo == \"valor\"):\n",
    "        valor_cnt += 1\n",
    "    elif (tipo == \"abstraccao\"):\n",
    "        abstraccao_cnt += 1\n",
    "    elif (tipo == \"coisa\"):\n",
    "        coisa_cnt += 1\n",
    "    elif (tipo == \"outro\"):\n",
    "        outro_cnt += 1\n",
    "        \n",
    "print(\"TOTAL = \" + str(total_cnt))\n",
    "print(\"INDIVIDUO = \" + str(individuo_cnt))\n",
    "print(\"VIRTUAL = \" + str(virtual_cnt))\n",
    "print(\"LOCAL = \" + str(local_cnt))\n",
    "print(\"ORGANIZACAO = \" + str(organizacao_cnt))\n",
    "print(\"GRUPO = \" + str(grupo_cnt))\n",
    "print(\"OBRA = \" + str(obra_cnt))\n",
    "print(\"ACONTECIMENTO = \" + str(acontecimento_cnt))\n",
    "print(\"DISCIPLINA = \" + str(disciplina_cnt))\n",
    "print(\"TEMPO = \" + str(tempo_cnt))\n",
    "print(\"VALOR = \" + str(valor_cnt))\n",
    "print(\"ABSTRACCAO = \" + str(abstraccao_cnt))\n",
    "print(\"COISA = \" + str(coisa_cnt))\n",
    "print(\"OUTRO = \" + str(outro_cnt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DISTRIBUIÇAO COM 9 CLASSES DE ENTIDADES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL = 7817\n",
      "INDIVIDUO = 1774\n",
      "LOCAL = 1539\n",
      "ORGANIZACAO = 1459\n",
      "OBRA = 489\n",
      "ACONTECIMENTO = 323\n",
      "TEMPO = 1199\n",
      "VALOR = 352\n",
      "ABSTRACCAO = 292\n",
      "OUTRO = 390\n"
     ]
    }
   ],
   "source": [
    "individuo_cnt = 0\n",
    "local_cnt = 0\n",
    "organizacao_cnt = 0\n",
    "obra_cnt = 0\n",
    "acontecimento_cnt = 0\n",
    "tempo_cnt = 0\n",
    "valor_cnt = 0\n",
    "abstraccao_cnt = 0\n",
    "outro_cnt = 0\n",
    "total_cnt = 0\n",
    "\n",
    "for row, tipo in enumerate(df['tipo_final'].tolist()):\n",
    "    total_cnt += 1\n",
    "    \n",
    "    if (tipo == \"individuo\"):\n",
    "        individuo_cnt += 1\n",
    "    elif (tipo == \"virtual\"):\n",
    "        df.at[row, 'tipo_final'] = \"local\"\n",
    "        local_cnt += 1\n",
    "    elif (tipo == \"local\"):\n",
    "        local_cnt += 1\n",
    "    elif (tipo == \"organizacao\"):\n",
    "        organizacao_cnt += 1\n",
    "    elif (tipo == \"grupo\"):\n",
    "        df.at[row, 'tipo_final'] = \"organizacao\"\n",
    "        organizacao_cnt += 1\n",
    "    elif (tipo == \"obra\"):\n",
    "        obra_cnt += 1\n",
    "    elif (tipo == \"acontecimento\"):\n",
    "        acontecimento_cnt += 1\n",
    "    elif (tipo == \"disciplina\"):\n",
    "        df.at[row, 'tipo_final'] = \"abstraccao\"\n",
    "        abstraccao_cnt += 1\n",
    "    elif (tipo == \"tempo\"):\n",
    "        tempo_cnt += 1\n",
    "    elif (tipo == \"valor\"):\n",
    "        valor_cnt += 1\n",
    "    elif (tipo == \"abstraccao\"):\n",
    "        abstraccao_cnt += 1\n",
    "    elif (tipo == \"coisa\"):\n",
    "        df.at[row, 'tipo_final'] = \"outro\"\n",
    "        outro_cnt += 1\n",
    "    elif (tipo == \"outro\"):\n",
    "        outro_cnt += 1\n",
    "        \n",
    "print(\"TOTAL = \" + str(total_cnt))\n",
    "print(\"INDIVIDUO = \" + str(individuo_cnt))\n",
    "print(\"LOCAL = \" + str(local_cnt))\n",
    "print(\"ORGANIZACAO = \" + str(organizacao_cnt))\n",
    "print(\"OBRA = \" + str(obra_cnt))\n",
    "print(\"ACONTECIMENTO = \" + str(acontecimento_cnt))\n",
    "print(\"TEMPO = \" + str(tempo_cnt))\n",
    "print(\"VALOR = \" + str(valor_cnt))\n",
    "print(\"ABSTRACCAO = \" + str(abstraccao_cnt))\n",
    "print(\"OUTRO = \" + str(outro_cnt))\n",
    "\n",
    "df.to_csv(\"dataset_processed_5.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process relations types (remove or replace some relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "residente_de\n",
      "residente_de\n",
      "outra_edicao\n",
      "localizacao_de\n",
      "localizacao_de\n",
      "nomeado_por\n",
      "nomeado_por\n",
      "nomeado_por\n",
      "nomeado_por\n",
      "periodo_vida\n",
      "local_morte\n",
      "consequencia_de\n",
      "outra_edicao\n",
      "periodo_vida\n",
      "outra_edicao\n",
      "residente_de\n",
      "local_morte\n",
      "periodo_vida\n",
      "periodo_vida\n",
      "nomeado_por\n",
      "local_morte\n",
      "periodo_vida\n",
      "local_morte\n",
      "localizacao_de\n",
      "localizacao_de\n",
      "localizacao_de\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "entity_ids = df['entity_id']\n",
    "\n",
    "for entity_id in entity_ids:\n",
    "    # EX: tiporels_for_each_entity == autor_de natural_de participante_em\n",
    "    tiporels_for_each_entity = df.loc[df.entity_id == entity_id, \"tiporel\"].values[0]\n",
    "    \n",
    "    if (tiporels_for_each_entity):\n",
    "        # EX: tiporel_list = [autor_de, natural_de, participante_em]\n",
    "        tiporel_list = tiporels_for_each_entity.split()\n",
    "        \n",
    "        corel_list = df.loc[df.entity_id == entity_id, \"corel\"].values[0].split()\n",
    "        \n",
    "        final_tiporel_list = []\n",
    "        final_corel_list = []\n",
    "        \n",
    "        for index, tiporel in enumerate(tiporel_list):\n",
    "            # renomear o tipo de relação\n",
    "            if (tiporel == \"local_nascimento_de\"):\n",
    "                final_tiporel_list.append(\"natural_de\")\n",
    "                final_corel_list.append(corel_list[index])\n",
    "            elif (tiporel == \"nome_de\"):\n",
    "                final_tiporel_list.append(\"ident\")\n",
    "                final_corel_list.append(corel_list[index])\n",
    "            elif (tiporel == \"nome_de_ident\"):\n",
    "                final_tiporel_list.append(\"ident\")\n",
    "                final_corel_list.append(corel_list[index])\n",
    "            elif (tiporel == \"nome_de_obra_de\"):\n",
    "                final_tiporel_list.append(\"obra_de\")\n",
    "                final_corel_list.append(corel_list[index])\n",
    "            elif (tiporel == \"nome_de_data_de\"):\n",
    "                final_tiporel_list.append(\"datado_de\")\n",
    "                final_corel_list.append(corel_list[index])\n",
    "            elif (tiporel == \"nome_de_incluido\"):\n",
    "                final_tiporel_list.append(\"incluido\")\n",
    "                final_corel_list.append(corel_list[index])\n",
    "            elif (tiporel == \"nome_de_inclui\"):\n",
    "                final_tiporel_list.append(\"inclui\")\n",
    "                final_corel_list.append(corel_list[index])\n",
    "            elif (tiporel == \"nome_de_pratica_se\"):\n",
    "                final_tiporel_list.append(\"pratica_se\")\n",
    "                final_corel_list.append(corel_list[index])\n",
    "            elif (tiporel == \"nome_de_praticado_por\"):\n",
    "                final_tiporel_list.append(\"praticado_por\")\n",
    "                final_corel_list.append(corel_list[index])\n",
    "            elif (tiporel == \"nome_de_outrarel\"):\n",
    "                final_tiporel_list.append(\"outrarel\")\n",
    "                final_corel_list.append(corel_list[index])\n",
    "            elif (tiporel == \"nome_de_vinculo_inst\"):\n",
    "                final_tiporel_list.append(\"vinculo_inst\")\n",
    "                final_corel_list.append(corel_list[index])\n",
    "            elif (tiporel == \"ocorre_em\"):\n",
    "                final_tiporel_list.append(\"localizado_em\")\n",
    "                final_corel_list.append(corel_list[index])\n",
    "            # remover completamente a relação\n",
    "            elif (tiporel == \"consequencia_de\"\n",
    "                  or tiporel == \"localizacao_de\"\n",
    "                  or tiporel == \"local_morte\"\n",
    "                  or tiporel == \"nomeado_por\"\n",
    "                  or tiporel == \"outra_edicao\"\n",
    "                  or tiporel == \"periodo_vida\"\n",
    "                  or tiporel == \"residente_de\"):\n",
    "                print(tiporel)\n",
    "            # manter a relação\n",
    "            else:\n",
    "                final_tiporel_list.append(tiporel)\n",
    "                final_corel_list.append(corel_list[index])\n",
    "                \n",
    "        df.loc[df.entity_id == entity_id, \"corel\"] = \" \".join(final_corel_list)\n",
    "        df.loc[df.entity_id == entity_id, \"tiporel\"] = \" \".join(final_tiporel_list)\n",
    "\n",
    "df.to_csv(\"dataset_processed_6.csv\")  \n",
    "\n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate train and test folds by documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=10)\n",
    "\n",
    "fold = 0\n",
    "\n",
    "for train_docs_indexes, test_docs_indexes in kf.split(df[\"doc_index\"].unique()):\n",
    "    train_docs = []\n",
    "    test_docs = []\n",
    "    \n",
    "    for doc_index in train_docs_indexes:\n",
    "        doc = df.loc[df['doc_index'] == doc_index]\n",
    "        train_docs.append(doc)\n",
    "    train = pd.concat(train_docs, ignore_index=True)\n",
    "    train.to_csv(\"train_fold_\" + str(fold) + \".csv\")\n",
    "    \n",
    "    for doc_index in test_docs_indexes:\n",
    "        doc = df.loc[df['doc_index'] == doc_index]\n",
    "        test_docs.append(doc)\n",
    "    test = pd.concat(test_docs, ignore_index=True)\n",
    "    test.to_csv(\"test_fold_\" + str(fold) + \".csv\")\n",
    "    \n",
    "    fold += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PRINT STUFF..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4571\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "TIPO=autor_de\tTOTAL=54\n",
      "TIPO=causador_de\tTOTAL=22\n",
      "TIPO=data_de\tTOTAL=76\n",
      "TIPO=data_morte\tTOTAL=9\n",
      "TIPO=data_nascimento\tTOTAL=6\n",
      "TIPO=datado_de\tTOTAL=10\n",
      "TIPO=ident\tTOTAL=2201\n",
      "TIPO=inclui\tTOTAL=320\n",
      "TIPO=incluido\tTOTAL=507\n",
      "TIPO=localizado_em\tTOTAL=121\n",
      "TIPO=natural_de\tTOTAL=133\n",
      "TIPO=obra_de\tTOTAL=93\n",
      "TIPO=outrarel\tTOTAL=97\n",
      "TIPO=participante_em\tTOTAL=90\n",
      "TIPO=personagem_de\tTOTAL=14\n",
      "TIPO=pratica_se\tTOTAL=16\n",
      "TIPO=praticado_em\tTOTAL=42\n",
      "TIPO=praticado_por\tTOTAL=16\n",
      "TIPO=praticante_de\tTOTAL=26\n",
      "TIPO=produtor_de\tTOTAL=28\n",
      "TIPO=produzido_por\tTOTAL=22\n",
      "TIPO=propriedade_de\tTOTAL=18\n",
      "TIPO=proprietario_de\tTOTAL=20\n",
      "TIPO=relacao_familiar\tTOTAL=82\n",
      "TIPO=relacao_profissional\tTOTAL=17\n",
      "TIPO=residencia_de\tTOTAL=15\n",
      "TIPO=sede_de\tTOTAL=196\n",
      "TIPO=ter_participacao_de\tTOTAL=64\n",
      "TIPO=vinculo_inst\tTOTAL=256\n"
     ]
    }
   ],
   "source": [
    "### PRINTAR TODAS AS RELAÇOES\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"dataset_processed_6.csv\")\n",
    "counter = 0\n",
    "dic = {}\n",
    "for tiporel in df[\"tiporel\"]:\n",
    "    if(tiporel == tiporel):\n",
    "        tipolist = tiporel.split()\n",
    "        for tipo in tipolist:\n",
    "            if (\"*\" in tipo):\n",
    "                words_list = tiporel.split(\"**\")\n",
    "                relation = words_list[1]\n",
    "            else:\n",
    "                relation = tipo\n",
    "            counter +=1\n",
    "            if(relation in dic):\n",
    "                dic[relation] += 1\n",
    "            else:\n",
    "                dic[relation] = 1\n",
    "print(counter)\n",
    "print(\"\\n\\n\")\n",
    "keys = list(dic.keys())\n",
    "keys.sort()\n",
    "print(\"\\n\\n\")\n",
    "for tipo in keys:\n",
    "    print(\"TIPO={}\\tTOTAL={}\".format(tipo, dic[tipo]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "TIPO=abstraccao\tTOTAL=292\n",
      "TIPO=acontecimento\tTOTAL=323\n",
      "TIPO=individuo\tTOTAL=1774\n",
      "TIPO=local\tTOTAL=1539\n",
      "TIPO=obra\tTOTAL=489\n",
      "TIPO=organizacao\tTOTAL=1459\n",
      "TIPO=outro\tTOTAL=390\n",
      "TIPO=tempo\tTOTAL=1199\n",
      "TIPO=valor\tTOTAL=352\n"
     ]
    }
   ],
   "source": [
    "### PRINTAR TODAS AS ENTIDADES\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"dataset_processed_6.csv\")\n",
    "counter = 0\n",
    "dic = {}\n",
    "for categ in df[\"tipo_final\"]:\n",
    "    if(categ == categ):\n",
    "        categlist = categ.split(\"|\")\n",
    "        for entity in categlist:\n",
    "            if(entity in dic):\n",
    "                dic[entity] += 1\n",
    "            else:\n",
    "                dic[entity] = 1\n",
    "print(counter)\n",
    "print(\"\\n\\n\")\n",
    "keys = list(dic.keys())\n",
    "keys.sort()\n",
    "print(\"\\n\\n\")\n",
    "for tipo in keys:\n",
    "    print(\"TIPO={}\\tTOTAL={}\".format(tipo, dic[tipo]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
